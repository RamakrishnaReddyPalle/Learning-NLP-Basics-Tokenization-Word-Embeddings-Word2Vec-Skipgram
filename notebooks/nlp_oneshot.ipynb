{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***NATURAL LANGUAGE PROCESSING***\n",
    "______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TEXT-PREPROCESSING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in d:\\anaconda_navigator\\envs\\nlp_env\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in d:\\anaconda_navigator\\envs\\nlp_env\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in d:\\anaconda_navigator\\envs\\nlp_env\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\anaconda_navigator\\envs\\nlp_env\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda_navigator\\envs\\nlp_env\\lib\\site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: colorama in d:\\anaconda_navigator\\envs\\nlp_env\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***a) Tokenization***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name is ram.\n",
      "I am from IIT Bhubaneswar! Studying there. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "corpus=\"\"\"My name is ram.\n",
    "I am from IIT Bhubaneswar! Studying there. \n",
    "\"\"\"\n",
    "\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\PMKR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenization (Sentance-->paragraphs)\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = sent_tokenize(corpus)\n",
    "type(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name is ram.\n",
      "I am from IIT Bhubaneswar!\n",
      "Studying there.\n"
     ]
    }
   ],
   "source": [
    "for sentence in documents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Next tokenization: para-> words or semtemce->words\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My',\n",
       " 'name',\n",
       " 'is',\n",
       " 'ram',\n",
       " '.',\n",
       " 'I',\n",
       " 'am',\n",
       " 'from',\n",
       " 'IIT',\n",
       " 'Bhubaneswar',\n",
       " '!',\n",
       " 'Studying',\n",
       " 'there',\n",
       " '.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My', 'name', 'is', 'ram', '.']\n",
      "['I', 'am', 'from', 'IIT', 'Bhubaneswar', '!']\n",
      "['Studying', 'there', '.']\n"
     ]
    }
   ],
   "source": [
    "for sentence in documents:\n",
    "    print(word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize # to treat punctuation marks also as seperate words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My',\n",
       " 'name',\n",
       " 'is',\n",
       " 'ram',\n",
       " '.',\n",
       " 'I',\n",
       " 'am',\n",
       " 'from',\n",
       " 'IIT',\n",
       " 'Bhubaneswar',\n",
       " '!',\n",
       " 'Studying',\n",
       " 'there',\n",
       " '.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordpunct_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My',\n",
       " 'name',\n",
       " 'is',\n",
       " 'ram.',\n",
       " 'I',\n",
       " 'am',\n",
       " 'from',\n",
       " 'IIT',\n",
       " 'Bhubaneswar',\n",
       " '!',\n",
       " 'Studying',\n",
       " 'there',\n",
       " '.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## tree bank word tokenizer \n",
    "# ( \".\" wont be treated as seperate word, but last fullstop is seperate word)\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "tokenizer.tokenize(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***b) Stemming***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reducing words to its word stem that affixes to suffixes \n",
    "# and prefixes or the roots of word known as lemma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Classification Problem example\n",
    "## Comments of products is positive or negative?\n",
    "\n",
    "words = [\"eating\",\"eats\",\"eaten\",\"writing\",\n",
    "         \"writes\",\"written\",\"programming\",\n",
    "         \"program\",\"history\",\"finally\",\"finalized\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Porter stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemming = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating----->eat\n",
      "eats----->eat\n",
      "eaten----->eaten\n",
      "writing----->write\n",
      "writes----->write\n",
      "written----->written\n",
      "programming----->program\n",
      "program----->program\n",
      "history----->histori\n",
      "finally----->final\n",
      "finalized----->final\n"
     ]
    }
   ],
   "source": [
    "for word in words: ## look at history (major disadvantage of stemmimg)\n",
    "    print(word+\"----->\"+stemming.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congatul'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem('congatulations') ## no meaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) RegexpStemmer class\n",
    "* Regular expression stemmer class.\n",
    "* With its help, NLTK can easily implement Regular expression stemmer algorithms.\n",
    "* Takes a single regular expression and removes any prefix or suffix that matches the expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "\n",
    "regstemmer = RegexpStemmer('ing$|s$|e$|able$', min=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ingeat'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regstemmer.stem('ingeating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Snowball stemmer\n",
    "\n",
    "* Better than poter stemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer ## provided with many languages\n",
    "\n",
    "sbstemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating---->eat\n",
      "eats---->eat\n",
      "eaten---->eaten\n",
      "writing---->write\n",
      "writes---->write\n",
      "written---->written\n",
      "programming---->program\n",
      "program---->program\n",
      "history---->histori\n",
      "finally---->final\n",
      "finalized---->final\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"---->\"+sbstemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fairli', 'sportingli')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem(\"fairly\"), stemming.stem(\"sportingly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fair', 'sport')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbstemmer.stem(\"fairly\"), sbstemmer.stem(\"sportingly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## better performance than porter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization solves all these issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***c) Lemmatization***\n",
    "\n",
    "* Its like stemmimg\n",
    "* The output after lemmatizing is called lemma\n",
    "* Lemma is a root word rather than root stem (o/p of stemming)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\PMKR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## qna, chatbots, text summarization, etc\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"going\",pos='v')\n",
    "\n",
    "\n",
    "## this function has two parameters: word and pos\n",
    "#POS: noun-n, verb-v, adjective-a, adverb-r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'going'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"going\",pos='n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating---->eat\n",
      "eats---->eat\n",
      "eaten---->eat\n",
      "writing---->write\n",
      "writes---->write\n",
      "written---->write\n",
      "programming---->program\n",
      "program---->program\n",
      "history---->history\n",
      "finally---->finally\n",
      "finalized---->finalize\n"
     ]
    }
   ],
   "source": [
    "for word in words: # check history\n",
    "    print(word+\"---->\"+lemmatizer.lemmatize(word,pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization takes times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***d) Stopwords***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "para = \"\"\"Dreams are not those which come while we are sleeping, but dreams are those when you don’t sleep before fulfilling them. My dear friends, let us ignite our minds and embrace the power of dreams. As a nation, we have the potential to reach great heights, but this can only be achieved through hard work, perseverance, and a relentless pursuit of excellence. Each one of us has a unique talent, and it is our duty to identify and nurture these talents to contribute to the progress of our nation. Education and innovation are the pillars of a strong society, and it is imperative that we equip our youth with the skills and knowledge required to tackle the challenges of the future. Remember, the future belongs to those who believe in the beauty of their dreams and are willing to work tirelessly to turn those dreams into reality. Let us pledge to be lifelong learners, to inspire and uplift each other, and to work collectively towards building a prosperous and harmonious India. Together, we can transform our country into a land of opportunity and success, where every citizen can achieve their fullest potential.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\PMKR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english') # try german french"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dreams are not those which come while we are sleeping, but dreams are those when you don’t sleep before fulfilling them.',\n",
       " 'My dear friends, let us ignite our minds and embrace the power of dreams.',\n",
       " 'As a nation, we have the potential to reach great heights, but this can only be achieved through hard work, perseverance, and a relentless pursuit of excellence.',\n",
       " 'Each one of us has a unique talent, and it is our duty to identify and nurture these talents to contribute to the progress of our nation.',\n",
       " 'Education and innovation are the pillars of a strong society, and it is imperative that we equip our youth with the skills and knowledge required to tackle the challenges of the future.',\n",
       " 'Remember, the future belongs to those who believe in the beauty of their dreams and are willing to work tirelessly to turn those dreams into reality.',\n",
       " 'Let us pledge to be lifelong learners, to inspire and uplift each other, and to work collectively towards building a prosperous and harmonious India.',\n",
       " 'Together, we can transform our country into a land of opportunity and success, where every citizen can achieve their fullest potential.']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = nltk.sent_tokenize(para)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply stopwords, then stemming\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    words = [stemmer.stem(word) for word in words if word.lower() not in set(stopwords.words('english'))]\n",
    "    sentences[i] = ' '.join(words) #converts all words to sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dream come sleep , dream ’ sleep fulfil .\n",
      "dear friend , let us ignit mind embrac power dream .\n",
      "nation , potenti reach great height , achiev hard work , persever , relentless pursuit excel .\n",
      "one us uniqu talent , duti identifi nurtur talent contribut progress nation .\n",
      "educ innov pillar strong societi , imper equip youth skill knowledg requir tackl challeng futur .\n",
      "rememb , futur belong believ beauti dream will work tirelessli turn dream realiti .\n",
      "let us pledg lifelong learner , inspir uplift , work collect toward build prosper harmoni india .\n",
      "togeth , transform countri land opportun success , everi citizen achiev fullest potenti .\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer ## provided with many languages\n",
    "\n",
    "sbstemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    words = [sbstemmer.stem(word) for word in words if word.lower() not in set(stopwords.words('english'))]\n",
    "    sentences[i] = ' '.join(words) #converts all words to sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dream come sleep , dream ’ sleep fulfil .',\n",
       " 'dear friend , let us ignit mind embrac power dream .',\n",
       " 'nation , potenti reach great height , achiev hard work , persev , relentless pursuit excel .',\n",
       " 'one us uniqu talent , duti identifi nurtur talent contribut progress nation .',\n",
       " 'educ innov pillar strong societi , imper equip youth skill knowledg requir tackl challeng futur .',\n",
       " 'rememb , futur belong believ beauti dream work tireless turn dream realiti .',\n",
       " 'let us pledg lifelong learner , inspir uplift , work collect toward build prosper harmoni india .',\n",
       " 'togeth , transform countri land opportun success , everi citizen achiev fullest potenti .']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    words = [lemmatizer.lemmatize(word.upper(),pos='v') for word in words if word.lower() not in set(stopwords.words('english'))]\n",
    "    sentences[i] = ' '.join(words) #converts all words to sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DREAM COME SLEEP , DREAM ’ SLEEP FULFIL .',\n",
       " 'DEAR FRIEND , LET US IGNIT MIND EMBRAC POWER DREAM .',\n",
       " 'NATION , POTENTI REACH GREAT HEIGHT , ACHIEV HARD WORK , PERSEV , RELENTLESS PURSUIT EXCEL .',\n",
       " 'ONE US UNIQU TALENT , DUTI IDENTIFI NURTUR TALENT CONTRIBUT PROGRESS NATION .',\n",
       " 'EDUC INNOV PILLAR STRONG SOCIETI , IMPER EQUIP YOUTH SKILL KNOWLEDG REQUIR TACKL CHALLENG FUTUR .',\n",
       " 'REMEMB , FUTUR BELONG BELIEV BEAUTI DREAM WORK TIRELESS TURN DREAM REALITI .',\n",
       " 'LET US PLEDG LIFELONG LEARNER , INSPIR UPLIFT , WORK COLLECT TOWARD BUILD PROSPER HARMONI INDIA .',\n",
       " 'TOGETH , TRANSFORM COUNTRI LAND OPPORTUN SUCCESS , EVERI CITIZEN ACHIEV FULLEST POTENTI .']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences # getting good output now! and upper/lower function changes the case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Parts of speech tagging***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dreams are not those which come while we are sleeping, but dreams are those when you don’t sleep before fulfilling them.',\n",
       " 'My dear friends, let us ignite our minds and embrace the power of dreams.',\n",
       " 'As a nation, we have the potential to reach great heights, but this can only be achieved through hard work, perseverance, and a relentless pursuit of excellence.',\n",
       " 'Each one of us has a unique talent, and it is our duty to identify and nurture these talents to contribute to the progress of our nation.',\n",
       " 'Education and innovation are the pillars of a strong society, and it is imperative that we equip our youth with the skills and knowledge required to tackle the challenges of the future.',\n",
       " 'Remember, the future belongs to those who believe in the beauty of their dreams and are willing to work tirelessly to turn those dreams into reality.',\n",
       " 'Let us pledge to be lifelong learners, to inspire and uplift each other, and to work collectively towards building a prosperous and harmonious India.',\n",
       " 'Together, we can transform our country into a land of opportunity and success, where every citizen can achieve their fullest potential.']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "sentences = nltk.sent_tokenize(para)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\PMKR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Dreams', 'NNP'), ('come', 'VBP'), ('sleeping', 'NN'), (',', ','), ('dreams', 'VBZ'), ('’', 'JJ'), ('sleep', 'JJ'), ('fulfilling', 'NN'), ('.', '.')]\n",
      "[('dear', 'JJ'), ('friends', 'NNS'), (',', ','), ('let', 'VB'), ('us', 'PRP'), ('ignite', 'VB'), ('minds', 'NNS'), ('embrace', 'JJ'), ('power', 'NN'), ('dreams', 'NNS'), ('.', '.')]\n",
      "[('nation', 'NN'), (',', ','), ('potential', 'JJ'), ('reach', 'NN'), ('great', 'JJ'), ('heights', 'NNS'), (',', ','), ('achieved', 'VBN'), ('hard', 'JJ'), ('work', 'NN'), (',', ','), ('perseverance', 'NN'), (',', ','), ('relentless', 'NN'), ('pursuit', 'NN'), ('excellence', 'NN'), ('.', '.')]\n",
      "[('one', 'CD'), ('us', 'PRP'), ('unique', 'JJ'), ('talent', 'NN'), (',', ','), ('duty', 'NN'), ('identify', 'JJ'), ('nurture', 'NN'), ('talents', 'NNS'), ('contribute', 'JJ'), ('progress', 'NN'), ('nation', 'NN'), ('.', '.')]\n",
      "[('Education', 'NN'), ('innovation', 'NN'), ('pillars', 'VBZ'), ('strong', 'JJ'), ('society', 'NN'), (',', ','), ('imperative', 'JJ'), ('equip', 'NN'), ('youth', 'NN'), ('skills', 'NNS'), ('knowledge', 'NN'), ('required', 'VBN'), ('tackle', 'NN'), ('challenges', 'VBZ'), ('future', 'NN'), ('.', '.')]\n",
      "[('Remember', 'NNP'), (',', ','), ('future', 'JJ'), ('belongs', 'NNS'), ('believe', 'VBP'), ('beauty', 'NN'), ('dreams', 'NNS'), ('willing', 'JJ'), ('work', 'NN'), ('tirelessly', 'RB'), ('turn', 'JJ'), ('dreams', 'JJ'), ('reality', 'NN'), ('.', '.')]\n",
      "[('Let', 'VB'), ('us', 'PRP'), ('pledge', 'VB'), ('lifelong', 'JJ'), ('learners', 'NNS'), (',', ','), ('inspire', 'NN'), ('uplift', 'NN'), (',', ','), ('work', 'NN'), ('collectively', 'RB'), ('towards', 'IN'), ('building', 'VBG'), ('prosperous', 'JJ'), ('harmonious', 'JJ'), ('India', 'NNP'), ('.', '.')]\n",
      "[('Together', 'RB'), (',', ','), ('transform', 'VB'), ('country', 'NN'), ('land', 'NN'), ('opportunity', 'NN'), ('success', 'NN'), (',', ','), ('every', 'DT'), ('citizen', 'NN'), ('achieve', 'VBP'), ('fullest', 'JJS'), ('potential', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# finding the POS tag (no need for stemming as i want to know about all words)\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    words = [word for word in words if word.lower() not in set(stopwords.words('english'))]\n",
    "    #sentences[i] = ' '.join(words)\n",
    "    pos_tag = nltk.pos_tag(words)\n",
    "    print(pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['taj', 'mahal', 'is', 'a', 'beautiful', 'thing.']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"taj mahal is a beautiful thing.\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('taj', 'NN'), ('mahal', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('beautiful', 'JJ'), ('thing.', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "print(nltk.pos_tag(\"taj mahal is a beautiful thing.\".split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Named entity recognition***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Elon Musk announced at the Tesla headquarters in Palo Alto that the company will release its latest electric car model, the Model Z, by the end of 2024.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\PMKR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\PMKR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Elon',\n",
       " 'Musk',\n",
       " 'announced',\n",
       " 'at',\n",
       " 'the',\n",
       " 'Tesla',\n",
       " 'headquarters',\n",
       " 'in',\n",
       " 'Palo',\n",
       " 'Alto',\n",
       " 'that',\n",
       " 'the',\n",
       " 'company',\n",
       " 'will',\n",
       " 'release',\n",
       " 'its',\n",
       " 'latest',\n",
       " 'electric',\n",
       " 'car',\n",
       " 'model',\n",
       " ',',\n",
       " 'the',\n",
       " 'Model',\n",
       " 'Z',\n",
       " ',',\n",
       " 'by',\n",
       " 'the',\n",
       " 'end',\n",
       " 'of',\n",
       " '2024',\n",
       " '.']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "words = nltk.word_tokenize(sentence)\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_elements = nltk.pos_tag(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"168px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight: normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,1568.0,168.0\" width=\"1568px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">S</text></svg><svg width=\"4.08163%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">PERSON</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">Elon</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"2.04082%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"4.08163%\" x=\"4.08163%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">PERSON</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">Musk</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"6.12245%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"5.61224%\" x=\"8.16327%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">announced</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VBD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"10.9694%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"2.04082%\" x=\"13.7755%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">at</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"14.7959%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"2.55102%\" x=\"15.8163%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">the</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">DT</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"17.0918%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"3.57143%\" x=\"18.3673%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">GPE</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">Tesla</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"20.1531%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"7.14286%\" x=\"21.9388%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">headquarters</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"25.5102%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"2.04082%\" x=\"29.0816%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">in</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"30.102%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"3.06122%\" x=\"31.1224%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">GPE</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">Palo</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"32.6531%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"3.06122%\" x=\"34.1837%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">Alto</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"35.7143%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"3.06122%\" x=\"37.2449%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">that</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"38.7755%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"2.55102%\" x=\"40.3061%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">the</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">DT</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"41.5816%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"4.59184%\" x=\"42.8571%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">company</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"45.1531%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"3.06122%\" x=\"47.449%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">will</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">MD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"48.9796%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"4.59184%\" x=\"50.5102%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">release</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VB</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"52.8061%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"3.06122%\" x=\"55.102%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">its</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">PRP$</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"56.6327%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"4.08163%\" x=\"58.1633%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">latest</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">JJS</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"60.2041%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"5.10204%\" x=\"62.2449%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">electric</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">JJ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"64.7959%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"2.55102%\" x=\"67.3469%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">car</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"68.6224%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"3.57143%\" x=\"69.898%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">model</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"71.6837%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"1.53061%\" x=\"73.4694%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">,</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">,</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"74.2347%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"2.55102%\" x=\"75%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">the</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">DT</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"76.2755%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"7.14286%\" x=\"77.551%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">ORGANIZATION</text></svg><svg width=\"58.3333%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">Model</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"29.1667%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"41.6667%\" x=\"58.3333%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">Z</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"79.1667%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"81.1224%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"1.53061%\" x=\"84.6939%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">,</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">,</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"85.4592%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"2.04082%\" x=\"86.2245%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">by</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"87.2449%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"2.55102%\" x=\"88.2653%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">the</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">DT</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"89.5408%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"2.55102%\" x=\"90.8163%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">end</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"92.0918%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"2.04082%\" x=\"93.3673%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">of</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"94.3878%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"3.06122%\" x=\"95.4082%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">2024</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">CD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"96.9388%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"1.53061%\" x=\"98.4694%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">.</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"99.2347%\" y1=\"19.2px\" y2=\"48px\" /></svg>"
      ],
      "text/plain": [
       "Tree('S', [Tree('PERSON', [('Elon', 'NNP')]), Tree('PERSON', [('Musk', 'NNP')]), ('announced', 'VBD'), ('at', 'IN'), ('the', 'DT'), Tree('GPE', [('Tesla', 'NNP')]), ('headquarters', 'NN'), ('in', 'IN'), Tree('GPE', [('Palo', 'NNP')]), ('Alto', 'NNP'), ('that', 'IN'), ('the', 'DT'), ('company', 'NN'), ('will', 'MD'), ('release', 'VB'), ('its', 'PRP$'), ('latest', 'JJS'), ('electric', 'JJ'), ('car', 'NN'), ('model', 'NN'), (',', ','), ('the', 'DT'), Tree('ORGANIZATION', [('Model', 'NNP'), ('Z', 'NNP')]), (',', ','), ('by', 'IN'), ('the', 'DT'), ('end', 'NN'), ('of', 'IN'), ('2024', 'CD'), ('.', '.')])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Named entity chunker\n",
    "# Updated chunker version directly uses svgimage and draws graph\n",
    "\n",
    "nltk.ne_chunk(tag_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Various encoding methods**\n",
    "\n",
    "### ***a) One Hot Encoding***\n",
    "**Advantages:**\n",
    "1) Easy to implement in python\n",
    "2) sklearn, onehotencoder, pd.get_dummies() etc\n",
    "\n",
    "**Disadvantages:**\n",
    "1) We get sparse matrices -> causes overfitting (runs on train but fails on test data)\n",
    "2) ML algo needs fixed size inputs\n",
    "3) No semantic meaning is getting captured (feature relation)\n",
    "4) Out of vocabulary words will fail the test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***b) Bag of Words*** (BOW)\n",
    "\n",
    "* Binary BOW (1s and 0s)\n",
    "* Normal BOW (based on freq, value increases)\n",
    "\n",
    "**Advantages:**\n",
    "1) Simple and intutive\n",
    "2) Getting fixed size inputs\n",
    "\n",
    "**Disadvantages:**\n",
    "1) Sparse matrix problem is still there\n",
    "2) Order of words isnt being considered\n",
    "3) Out of vocabulary still exists\n",
    "4) Semantic meaning still not getting captured\n",
    "\n",
    "### ***c) TF-TDF*** *Term Frequency - Inverse Document Frequency*\n",
    "\n",
    "1) *TF:*\n",
    "$$\n",
    "\\text{TF}(t) = \\frac{\\text{Number of repetitions of term } t \\text{ in a sentence}}{\\text{Total number of words in the sentence}}\n",
    "$$\n",
    "\n",
    "2) *IDF:*\n",
    "$$\n",
    "\\text{IDF}(t) = \\ln \\left( \\frac{\\text{Total number of sentences}}{\\text{Number of sentences containing term } t} \\right)\n",
    "$$\n",
    "\n",
    "3) *Combined TF-IDF:*\n",
    "$$\n",
    "\\text{TF-IDF}(t) = \\text{TF}(t) \\times \\text{IDF}(t)\n",
    "$$\n",
    "\n",
    "**Advantages:**\n",
    "1) intutive\n",
    "2) Getting fixed size inputs\n",
    "3) Word importance is getting captured (repititive words score will be less)\n",
    "\n",
    "**Disadvantages:**\n",
    "1) Sparse matrix problem is still there\n",
    "2) Order of words isnt being considered\n",
    "3) Out of vocabulary still exists\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Word Embeddings**\n",
    "* It is a term used for the representation of words for text analysis, typically in the form of a real-valued vector that encodes the meaning of the word such that the words that are closer in the vector space are expected to be similar in meaning.\n",
    "\n",
    "* Two types:\n",
    "    * Count or frequency:\n",
    "        1) One hot encoding\n",
    "        2) BOW\n",
    "        3) TF-IDF\n",
    "    * Deep learning trained models:\n",
    "        * Word2Vec:\n",
    "            1) CBOW (continuous bag of words)\n",
    "            2) Skipgram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Word2Vec***\n",
    "*(Google-2013)*\n",
    "\n",
    "* NLP technique that uses a neural network model to learn word associations from a large corpus of text. \n",
    "* Once trained, such a model can detect synonyms or suggest additional words for a partial sentence.\n",
    "* Each distinct word is represented with particular vectors.\n",
    "* Cosine similarity:\n",
    "    $$\n",
    "    \\text{Distance} = (1-cosine similarity)\n",
    "    $$\n",
    "\n",
    "#### ***CBOW:***\n",
    "* Fully connected neural network\n",
    "    * Window size = n (middle layer with n neurons)\n",
    "    * Input layer = one hot encoded, n-1 vectors, each of size = length of vocabulary\n",
    "    * output layer= length of vocabulary\n",
    "\n",
    "#### ***Skipgram:***\n",
    "* IP OP of CBOW reversed\n",
    "* Softmax at op\n",
    "\n",
    "**Additional info:**\n",
    "* When should we apply CBOW or Skipgram?\n",
    "    * Small dataset: **CBOW**\n",
    "    * Huge dataset: **Skipgram**\n",
    "\n",
    "* Increase training data.\n",
    "* Increase in window size leads to increase in vector dimensions.\n",
    "* Google Word2Vec: (*pretrained*)\n",
    "    * 3 Billion Words\n",
    "    * Feature representation of 300 dimensions vector\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in d:\\anaconda_navigator\\envs\\nlp_env\\lib\\site-packages (4.3.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in d:\\anaconda_navigator\\envs\\nlp_env\\lib\\site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.7.0 in d:\\anaconda_navigator\\envs\\nlp_env\\lib\\site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in d:\\anaconda_navigator\\envs\\nlp_env\\lib\\site-packages (from gensim) (7.0.4)\n",
      "Requirement already satisfied: wrapt in d:\\anaconda_navigator\\envs\\nlp_env\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Google pretrained Word2vec model\n",
    "# Gensim, Glove\n",
    "\n",
    "%pip install gensim\n",
    "# Before installing gensim, go to: https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
    "# 1) Download Buld Tools\n",
    "# 2) Install and run the application\n",
    "# 3) During the installation, select the \"Desktop development with C++\" workload. \n",
    "#    Make sure to check the \"MSVC v142 - VS 2019 C++ x64/x86 build tools\" option.\n",
    "# Then pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import triu\n",
    "\n",
    "# Latsest version of scipy doesnt have triu on which gensim is dependent.\n",
    "# Hence, installed scipy==1.12\n",
    "# pip install scipy==1.12\n",
    "# pip install --upgrade gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "wv = api.load('word2vec-google-news-300')\n",
    "vec_king = wv['king']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.25976562e-01,  2.97851562e-02,  8.60595703e-03,  1.39648438e-01,\n",
       "       -2.56347656e-02, -3.61328125e-02,  1.11816406e-01, -1.98242188e-01,\n",
       "        5.12695312e-02,  3.63281250e-01, -2.42187500e-01, -3.02734375e-01,\n",
       "       -1.77734375e-01, -2.49023438e-02, -1.67968750e-01, -1.69921875e-01,\n",
       "        3.46679688e-02,  5.21850586e-03,  4.63867188e-02,  1.28906250e-01,\n",
       "        1.36718750e-01,  1.12792969e-01,  5.95703125e-02,  1.36718750e-01,\n",
       "        1.01074219e-01, -1.76757812e-01, -2.51953125e-01,  5.98144531e-02,\n",
       "        3.41796875e-01, -3.11279297e-02,  1.04492188e-01,  6.17675781e-02,\n",
       "        1.24511719e-01,  4.00390625e-01, -3.22265625e-01,  8.39843750e-02,\n",
       "        3.90625000e-02,  5.85937500e-03,  7.03125000e-02,  1.72851562e-01,\n",
       "        1.38671875e-01, -2.31445312e-01,  2.83203125e-01,  1.42578125e-01,\n",
       "        3.41796875e-01, -2.39257812e-02, -1.09863281e-01,  3.32031250e-02,\n",
       "       -5.46875000e-02,  1.53198242e-02, -1.62109375e-01,  1.58203125e-01,\n",
       "       -2.59765625e-01,  2.01416016e-02, -1.63085938e-01,  1.35803223e-03,\n",
       "       -1.44531250e-01, -5.68847656e-02,  4.29687500e-02, -2.46582031e-02,\n",
       "        1.85546875e-01,  4.47265625e-01,  9.58251953e-03,  1.31835938e-01,\n",
       "        9.86328125e-02, -1.85546875e-01, -1.00097656e-01, -1.33789062e-01,\n",
       "       -1.25000000e-01,  2.83203125e-01,  1.23046875e-01,  5.32226562e-02,\n",
       "       -1.77734375e-01,  8.59375000e-02, -2.18505859e-02,  2.05078125e-02,\n",
       "       -1.39648438e-01,  2.51464844e-02,  1.38671875e-01, -1.05468750e-01,\n",
       "        1.38671875e-01,  8.88671875e-02, -7.51953125e-02, -2.13623047e-02,\n",
       "        1.72851562e-01,  4.63867188e-02, -2.65625000e-01,  8.91113281e-03,\n",
       "        1.49414062e-01,  3.78417969e-02,  2.38281250e-01, -1.24511719e-01,\n",
       "       -2.17773438e-01, -1.81640625e-01,  2.97851562e-02,  5.71289062e-02,\n",
       "       -2.89306641e-02,  1.24511719e-02,  9.66796875e-02, -2.31445312e-01,\n",
       "        5.81054688e-02,  6.68945312e-02,  7.08007812e-02, -3.08593750e-01,\n",
       "       -2.14843750e-01,  1.45507812e-01, -4.27734375e-01, -9.39941406e-03,\n",
       "        1.54296875e-01, -7.66601562e-02,  2.89062500e-01,  2.77343750e-01,\n",
       "       -4.86373901e-04, -1.36718750e-01,  3.24218750e-01, -2.46093750e-01,\n",
       "       -3.03649902e-03, -2.11914062e-01,  1.25000000e-01,  2.69531250e-01,\n",
       "        2.04101562e-01,  8.25195312e-02, -2.01171875e-01, -1.60156250e-01,\n",
       "       -3.78417969e-02, -1.20117188e-01,  1.15234375e-01, -4.10156250e-02,\n",
       "       -3.95507812e-02, -8.98437500e-02,  6.34765625e-03,  2.03125000e-01,\n",
       "        1.86523438e-01,  2.73437500e-01,  6.29882812e-02,  1.41601562e-01,\n",
       "       -9.81445312e-02,  1.38671875e-01,  1.82617188e-01,  1.73828125e-01,\n",
       "        1.73828125e-01, -2.37304688e-01,  1.78710938e-01,  6.34765625e-02,\n",
       "        2.36328125e-01, -2.08984375e-01,  8.74023438e-02, -1.66015625e-01,\n",
       "       -7.91015625e-02,  2.43164062e-01, -8.88671875e-02,  1.26953125e-01,\n",
       "       -2.16796875e-01, -1.73828125e-01, -3.59375000e-01, -8.25195312e-02,\n",
       "       -6.49414062e-02,  5.07812500e-02,  1.35742188e-01, -7.47070312e-02,\n",
       "       -1.64062500e-01,  1.15356445e-02,  4.45312500e-01, -2.15820312e-01,\n",
       "       -1.11328125e-01, -1.92382812e-01,  1.70898438e-01, -1.25000000e-01,\n",
       "        2.65502930e-03,  1.92382812e-01, -1.74804688e-01,  1.39648438e-01,\n",
       "        2.92968750e-01,  1.13281250e-01,  5.95703125e-02, -6.39648438e-02,\n",
       "        9.96093750e-02, -2.72216797e-02,  1.96533203e-02,  4.27246094e-02,\n",
       "       -2.46093750e-01,  6.39648438e-02, -2.25585938e-01, -1.68945312e-01,\n",
       "        2.89916992e-03,  8.20312500e-02,  3.41796875e-01,  4.32128906e-02,\n",
       "        1.32812500e-01,  1.42578125e-01,  7.61718750e-02,  5.98144531e-02,\n",
       "       -1.19140625e-01,  2.74658203e-03, -6.29882812e-02, -2.72216797e-02,\n",
       "       -4.82177734e-03, -8.20312500e-02, -2.49023438e-02, -4.00390625e-01,\n",
       "       -1.06933594e-01,  4.24804688e-02,  7.76367188e-02, -1.16699219e-01,\n",
       "        7.37304688e-02, -9.22851562e-02,  1.07910156e-01,  1.58203125e-01,\n",
       "        4.24804688e-02,  1.26953125e-01,  3.61328125e-02,  2.67578125e-01,\n",
       "       -1.01074219e-01, -3.02734375e-01, -5.76171875e-02,  5.05371094e-02,\n",
       "        5.26428223e-04, -2.07031250e-01, -1.38671875e-01, -8.97216797e-03,\n",
       "       -2.78320312e-02, -1.41601562e-01,  2.07031250e-01, -1.58203125e-01,\n",
       "        1.27929688e-01,  1.49414062e-01, -2.24609375e-02, -8.44726562e-02,\n",
       "        1.22558594e-01,  2.15820312e-01, -2.13867188e-01, -3.12500000e-01,\n",
       "       -3.73046875e-01,  4.08935547e-03,  1.07421875e-01,  1.06933594e-01,\n",
       "        7.32421875e-02,  8.97216797e-03, -3.88183594e-02, -1.29882812e-01,\n",
       "        1.49414062e-01, -2.14843750e-01, -1.83868408e-03,  9.91210938e-02,\n",
       "        1.57226562e-01, -1.14257812e-01, -2.05078125e-01,  9.91210938e-02,\n",
       "        3.69140625e-01, -1.97265625e-01,  3.54003906e-02,  1.09375000e-01,\n",
       "        1.31835938e-01,  1.66992188e-01,  2.35351562e-01,  1.04980469e-01,\n",
       "       -4.96093750e-01, -1.64062500e-01, -1.56250000e-01, -5.22460938e-02,\n",
       "        1.03027344e-01,  2.43164062e-01, -1.88476562e-01,  5.07812500e-02,\n",
       "       -9.37500000e-02, -6.68945312e-02,  2.27050781e-02,  7.61718750e-02,\n",
       "        2.89062500e-01,  3.10546875e-01, -5.37109375e-02,  2.28515625e-01,\n",
       "        2.51464844e-02,  6.78710938e-02, -1.21093750e-01, -2.15820312e-01,\n",
       "       -2.73437500e-01, -3.07617188e-02, -3.37890625e-01,  1.53320312e-01,\n",
       "        2.33398438e-01, -2.08007812e-01,  3.73046875e-01,  8.20312500e-02,\n",
       "        2.51953125e-01, -7.61718750e-02, -4.66308594e-02, -2.23388672e-02,\n",
       "        2.99072266e-02, -5.93261719e-02, -4.66918945e-03, -2.44140625e-01,\n",
       "       -2.09960938e-01, -2.87109375e-01, -4.54101562e-02, -1.77734375e-01,\n",
       "       -2.79296875e-01, -8.59375000e-02,  9.13085938e-02,  2.51953125e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_king"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_king.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.67187500e-01, -1.21582031e-01,  2.85156250e-01,  8.15429688e-02,\n",
       "        3.19824219e-02, -3.19824219e-02,  1.34765625e-01, -2.73437500e-01,\n",
       "        9.46044922e-03, -1.07421875e-01,  2.48046875e-01, -6.05468750e-01,\n",
       "        5.02929688e-02,  2.98828125e-01,  9.57031250e-02,  1.39648438e-01,\n",
       "       -5.41992188e-02,  2.91015625e-01,  2.85156250e-01,  1.51367188e-01,\n",
       "       -2.89062500e-01, -3.46679688e-02,  1.81884766e-02, -3.92578125e-01,\n",
       "        2.46093750e-01,  2.51953125e-01, -9.86328125e-02,  3.22265625e-01,\n",
       "        4.49218750e-01, -1.36718750e-01, -2.34375000e-01,  4.12597656e-02,\n",
       "       -2.15820312e-01,  1.69921875e-01,  2.56347656e-02,  1.50146484e-02,\n",
       "       -3.75976562e-02,  6.95800781e-03,  4.00390625e-01,  2.09960938e-01,\n",
       "        1.17675781e-01, -4.19921875e-02,  2.34375000e-01,  2.03125000e-01,\n",
       "       -1.86523438e-01, -2.46093750e-01,  3.12500000e-01, -2.59765625e-01,\n",
       "       -1.06933594e-01,  1.04003906e-01, -1.79687500e-01,  5.71289062e-02,\n",
       "       -7.41577148e-03, -5.59082031e-02,  7.61718750e-02, -4.14062500e-01,\n",
       "       -3.65234375e-01, -3.35937500e-01, -1.54296875e-01, -2.39257812e-01,\n",
       "       -3.73046875e-01,  2.27355957e-03, -3.51562500e-01,  8.64257812e-02,\n",
       "        1.26953125e-01,  2.21679688e-01, -9.86328125e-02,  1.08886719e-01,\n",
       "        3.65234375e-01, -5.66406250e-02,  5.66406250e-02, -1.09375000e-01,\n",
       "       -1.66992188e-01, -4.54101562e-02, -2.00195312e-01, -1.22558594e-01,\n",
       "        1.31835938e-01, -1.31835938e-01,  1.03027344e-01, -3.41796875e-01,\n",
       "       -1.57226562e-01,  2.04101562e-01,  4.39453125e-02,  2.44140625e-01,\n",
       "       -3.19824219e-02,  3.20312500e-01, -4.41894531e-02,  1.08398438e-01,\n",
       "       -4.98046875e-02, -9.52148438e-03,  2.46093750e-01, -5.59082031e-02,\n",
       "        4.07714844e-02, -1.78222656e-02, -2.95410156e-02,  1.65039062e-01,\n",
       "        5.03906250e-01, -2.81250000e-01,  9.81445312e-02,  1.80664062e-02,\n",
       "       -1.83593750e-01,  2.53906250e-01,  2.25585938e-01,  1.63574219e-02,\n",
       "        1.81640625e-01,  1.38671875e-01,  3.33984375e-01,  1.39648438e-01,\n",
       "        1.45874023e-02, -2.89306641e-02, -8.39843750e-02,  1.50390625e-01,\n",
       "        1.67968750e-01,  2.28515625e-01,  3.59375000e-01,  1.22558594e-01,\n",
       "       -3.28125000e-01, -1.56250000e-01,  2.77343750e-01,  1.77001953e-02,\n",
       "       -1.46484375e-01, -4.51660156e-03, -4.46777344e-02,  1.75781250e-01,\n",
       "       -3.75000000e-01,  1.16699219e-01, -1.39648438e-01,  2.55859375e-01,\n",
       "       -1.96289062e-01, -2.57568359e-02, -5.41992188e-02, -2.51464844e-02,\n",
       "       -1.93359375e-01, -3.17382812e-02, -8.74023438e-02, -1.32812500e-01,\n",
       "       -2.12402344e-02,  4.33593750e-01, -5.20019531e-02,  3.46679688e-02,\n",
       "        8.00781250e-02,  3.41796875e-02,  1.99218750e-01, -2.39257812e-02,\n",
       "       -2.37304688e-01,  1.93359375e-01,  7.32421875e-02, -2.87109375e-01,\n",
       "        1.25000000e-01,  8.44726562e-02,  1.30859375e-01, -2.19726562e-01,\n",
       "       -1.61132812e-01, -2.63671875e-01, -5.46875000e-01, -2.96875000e-01,\n",
       "        3.44238281e-02, -2.87109375e-01, -1.93359375e-01, -1.61132812e-01,\n",
       "       -3.84765625e-01, -2.14843750e-01, -6.22558594e-03, -1.27929688e-01,\n",
       "       -1.00097656e-01, -6.21093750e-01,  3.78906250e-01, -4.58984375e-01,\n",
       "        1.44531250e-01, -9.13085938e-02, -3.08593750e-01,  2.23632812e-01,\n",
       "        7.86132812e-02, -2.16796875e-01,  8.78906250e-02, -1.66992188e-01,\n",
       "        1.14746094e-02, -2.53906250e-01, -6.25000000e-02,  6.04248047e-03,\n",
       "        1.56250000e-01,  4.37500000e-01, -2.23632812e-01, -2.32421875e-01,\n",
       "        2.75390625e-01,  2.39257812e-01,  4.49218750e-02, -7.51953125e-02,\n",
       "        5.74218750e-01, -2.61230469e-02, -1.21582031e-01,  2.44140625e-01,\n",
       "       -3.37890625e-01,  8.59375000e-02, -7.71484375e-02,  4.85839844e-02,\n",
       "        1.43554688e-01,  4.25781250e-01, -4.29687500e-02, -1.08398438e-01,\n",
       "        1.19628906e-01, -1.91406250e-01, -2.12890625e-01, -2.87109375e-01,\n",
       "       -1.14746094e-01, -2.04101562e-01, -2.06298828e-02, -2.53906250e-01,\n",
       "        8.25195312e-02, -3.97949219e-02, -1.57226562e-01,  1.34765625e-01,\n",
       "        2.08007812e-01, -1.78710938e-01, -2.00195312e-02, -8.34960938e-02,\n",
       "       -1.20605469e-01,  4.29687500e-02, -1.94335938e-01, -1.32812500e-01,\n",
       "       -2.17285156e-02, -2.35351562e-01, -3.63281250e-01,  1.51367188e-01,\n",
       "        9.32617188e-02,  1.63085938e-01,  1.02050781e-01, -4.27734375e-01,\n",
       "        2.83203125e-01,  2.74658203e-04, -3.20312500e-01,  1.68457031e-02,\n",
       "        4.06250000e-01, -5.24902344e-02,  7.91015625e-02, -1.41601562e-01,\n",
       "        5.27343750e-01, -1.26953125e-01,  4.74609375e-01, -6.64062500e-02,\n",
       "        3.41796875e-01, -1.78710938e-01,  3.69140625e-01, -2.05078125e-01,\n",
       "        5.82885742e-03, -1.84570312e-01, -8.88671875e-02, -1.81640625e-01,\n",
       "       -4.80957031e-02,  4.39453125e-01,  2.12890625e-01, -3.07617188e-02,\n",
       "        9.32617188e-02,  2.40234375e-01,  2.39257812e-01,  2.51953125e-01,\n",
       "       -1.98974609e-02,  1.24511719e-01, -4.73632812e-02, -2.13623047e-02,\n",
       "        3.12500000e-02,  3.05175781e-02,  2.79296875e-01,  9.08203125e-02,\n",
       "       -2.02148438e-01, -2.19726562e-02, -2.63671875e-01,  8.78906250e-02,\n",
       "       -1.07421875e-01, -2.49023438e-01, -1.22070312e-02,  1.73828125e-01,\n",
       "       -9.91210938e-02,  7.27539062e-02,  2.59765625e-01, -4.60937500e-01,\n",
       "        3.59375000e-01, -2.25585938e-01,  1.87988281e-02, -2.19726562e-01,\n",
       "       -2.08984375e-01, -1.51367188e-01,  8.64257812e-02,  1.11694336e-02,\n",
       "        6.93359375e-02, -2.99072266e-02,  1.43554688e-01,  1.89453125e-01,\n",
       "       -1.32812500e-01,  4.72656250e-01, -1.40625000e-01, -2.52685547e-02,\n",
       "        1.91406250e-01, -2.63671875e-01, -1.39648438e-01,  1.09375000e-01,\n",
       "        1.97753906e-02,  2.49023438e-01, -1.42578125e-01,  4.15039062e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv['cricket']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cricketing', 0.8372225761413574),\n",
       " ('cricketers', 0.8165745735168457),\n",
       " ('Test_cricket', 0.8094819784164429),\n",
       " ('Twenty##_cricket', 0.8068488240242004),\n",
       " ('Twenty##', 0.7624265551567078),\n",
       " ('Cricket', 0.7541396617889404),\n",
       " ('cricketer', 0.7372578382492065),\n",
       " ('twenty##', 0.7316356897354126),\n",
       " ('T##_cricket', 0.7304614186286926),\n",
       " ('West_Indies_cricket', 0.698798656463623)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar('cricket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5354152"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similarity(\"hockey\",\"sports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.29687500e-02, -1.78222656e-01, -1.29089355e-01,  1.15234375e-01,\n",
       "        2.68554688e-03, -1.02294922e-01,  1.95800781e-01, -1.79504395e-01,\n",
       "        1.95312500e-02,  4.09919739e-01, -3.68164062e-01, -3.96484375e-01,\n",
       "       -1.56738281e-01,  1.46484375e-03, -9.30175781e-02, -1.16455078e-01,\n",
       "       -5.51757812e-02, -1.07574463e-01,  7.91015625e-02,  1.98974609e-01,\n",
       "        2.38525391e-01,  6.34002686e-02, -2.17285156e-02,  0.00000000e+00,\n",
       "        4.72412109e-02, -2.17773438e-01, -3.44726562e-01,  6.37207031e-02,\n",
       "        3.16406250e-01, -1.97631836e-01,  8.59375000e-02, -8.11767578e-02,\n",
       "       -3.71093750e-02,  3.15551758e-01, -3.41796875e-01, -4.68750000e-02,\n",
       "        9.76562500e-02,  8.39843750e-02, -9.71679688e-02,  5.17578125e-02,\n",
       "       -5.00488281e-02, -2.20947266e-01,  2.29492188e-01,  1.26403809e-01,\n",
       "        2.49023438e-01,  2.09960938e-02, -1.09863281e-01,  5.81054688e-02,\n",
       "       -3.35693359e-02,  1.29577637e-01,  2.41699219e-02,  3.48129272e-02,\n",
       "       -2.60009766e-01,  2.42309570e-01, -3.21777344e-01,  1.45416260e-02,\n",
       "       -1.59179688e-01, -8.37402344e-02,  1.65039062e-01,  1.58691406e-03,\n",
       "        3.09570312e-01,  3.16406250e-01,  7.38525391e-03,  2.41210938e-01,\n",
       "        4.90722656e-02, -9.86328125e-02,  2.90527344e-02,  1.49414062e-01,\n",
       "       -4.83398438e-02,  2.35595703e-01,  2.21191406e-01,  1.25488281e-01,\n",
       "       -1.38671875e-01,  1.54296875e-01,  7.18994141e-02,  1.29882812e-01,\n",
       "       -1.05712891e-01,  6.00585938e-02,  3.14697266e-01,  1.09619141e-01,\n",
       "        8.49609375e-02,  7.71484375e-02, -2.17285156e-02,  6.11572266e-02,\n",
       "       -1.89941406e-01,  2.07519531e-01, -1.63085938e-01,  1.13525391e-01,\n",
       "        2.01171875e-01,  6.06689453e-02,  1.27929688e-01, -3.11279297e-01,\n",
       "       -2.80151367e-01, -1.55883789e-01,  4.15039062e-02,  9.87854004e-02,\n",
       "        1.69555664e-01, -3.49121094e-02,  2.08496094e-01, -9.89990234e-02,\n",
       "        4.39453125e-03, -7.27539062e-02, -4.24804688e-02, -4.09179688e-01,\n",
       "       -2.76367188e-01,  1.64062500e-01, -5.57617188e-01, -2.02199936e-01,\n",
       "        2.12158203e-01, -9.81445312e-02,  2.30773926e-01,  2.75878906e-01,\n",
       "        1.68092728e-01, -4.50439453e-02,  1.71615601e-01, -3.77075195e-01,\n",
       "       -3.52478027e-03, -3.01513672e-01,  1.74224854e-01,  3.30078125e-01,\n",
       "        2.00683594e-01,  1.17736816e-01, -1.37695312e-01, -1.07421875e-01,\n",
       "        8.61816406e-02,  1.06445312e-01,  1.44531250e-01,  3.05175781e-03,\n",
       "        1.80664062e-02,  3.73535156e-02,  7.32421875e-03,  1.32812500e-01,\n",
       "        9.61914062e-02,  3.35998535e-01,  1.81152344e-01,  2.40905762e-01,\n",
       "       -8.49609375e-02, -1.10107422e-01,  2.11914062e-01,  5.85937500e-03,\n",
       "        1.62109375e-01, -4.15527344e-01,  1.39160156e-01,  1.01562500e-01,\n",
       "        1.44531250e-01, -1.09375000e-01,  4.88281250e-02,  6.15234375e-02,\n",
       "       -1.69921875e-01,  3.28369141e-02,  5.56640625e-02,  1.47460938e-01,\n",
       "       -2.24609375e-02, -2.73925781e-01, -2.81982422e-01, -1.39160156e-01,\n",
       "       -1.81884766e-01,  9.33532715e-02,  1.21093750e-01, -5.37109375e-03,\n",
       "       -1.87500000e-01,  3.05175781e-04,  5.52734375e-01, -9.71679688e-02,\n",
       "       -1.81640625e-01, -1.51855469e-01,  7.76367188e-02, -2.38281250e-01,\n",
       "       -2.63977051e-02,  2.25555420e-01, -3.02734375e-01,  1.34765625e-01,\n",
       "        3.23242188e-01,  1.25976562e-01,  3.51562500e-02, -2.04345703e-01,\n",
       "        2.96142578e-01,  1.03149414e-01, -4.76074219e-03,  1.69189453e-01,\n",
       "       -3.50585938e-01,  2.46887207e-02, -3.90502930e-01, -2.70507812e-01,\n",
       "        1.85241699e-02,  1.04492188e-01,  2.84179688e-01,  1.35009766e-01,\n",
       "       -5.95703125e-02,  1.88232422e-01,  8.88214111e-02,  3.24707031e-02,\n",
       "       -8.98437500e-02,  5.45043945e-02,  5.65185547e-02,  1.56860352e-01,\n",
       "       -9.70458984e-03, -7.08007812e-02,  5.71289062e-02, -3.08837891e-01,\n",
       "       -1.91894531e-01,  4.83398438e-02,  5.22460938e-02, -1.59667969e-01,\n",
       "       -4.49218750e-02, -7.37304688e-02,  5.51757812e-02,  2.12402344e-01,\n",
       "        2.05322266e-01, -2.73437500e-02,  7.86132812e-02,  3.19091797e-01,\n",
       "       -1.56982422e-01, -3.92822266e-01,  4.00390625e-02,  9.93652344e-02,\n",
       "       -1.97372437e-02, -8.25195312e-02,  2.53906250e-02,  3.10668945e-02,\n",
       "       -3.63769531e-02,  1.48925781e-02,  2.20703125e-01, -5.98144531e-02,\n",
       "        6.15234375e-02, -7.14111328e-02, -4.00390625e-02, -1.03515625e-01,\n",
       "        9.22851562e-02,  2.71789551e-01, -2.30224609e-01, -2.62695312e-01,\n",
       "       -5.61523438e-01,  1.38549805e-02,  1.09863281e-01,  7.22656250e-02,\n",
       "        4.58984375e-02, -3.31802368e-02, -8.03833008e-02, -6.10351562e-03,\n",
       "        2.09960938e-01, -3.86840820e-01,  1.44645691e-01,  8.05664062e-02,\n",
       "        2.96264648e-01, -1.17187500e-02, -2.34680176e-01,  1.32019043e-01,\n",
       "        2.53906250e-01, -2.46826172e-01,  1.03759766e-01,  1.14013672e-01,\n",
       "        1.71875000e-01, -5.61523438e-03,  2.05078125e-01,  6.34765625e-02,\n",
       "       -4.51293945e-01, -2.26562500e-01, -1.03027344e-01, -1.31469727e-01,\n",
       "        3.75976562e-02,  2.70996094e-01, -2.39257812e-01,  3.80859375e-02,\n",
       "       -3.90625000e-02, -9.42382812e-02,  8.30078125e-03,  7.03125000e-02,\n",
       "        2.75390625e-01,  3.31542969e-01, -1.07421875e-02,  3.72192383e-01,\n",
       "       -1.24511719e-01,  1.94335938e-01, -1.35620117e-01, -3.09570312e-01,\n",
       "       -2.36328125e-01, -1.26953125e-02, -2.76855469e-01,  1.57714844e-01,\n",
       "        3.07617188e-01, -2.32910156e-01,  3.25439453e-01,  1.36718750e-02,\n",
       "        1.99462891e-01, -2.61840820e-02, -8.08105469e-02, -7.50732422e-02,\n",
       "       -4.11109924e-02,  1.95556641e-01, -5.64270020e-02, -2.79296875e-01,\n",
       "       -2.75390625e-01, -4.04296875e-01, -1.75781250e-02, -5.85937500e-03,\n",
       "       -7.71484375e-02,  1.33789062e-01,  2.36816406e-01,  2.01538086e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = wv['king']-wv['man']+wv['woman']\n",
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('king', 0.8449392318725586),\n",
       " ('queen', 0.7300518155097961),\n",
       " ('monarch', 0.645466148853302),\n",
       " ('princess', 0.6156251430511475),\n",
       " ('crown_prince', 0.5818676948547363),\n",
       " ('prince', 0.5777117609977722),\n",
       " ('kings', 0.5613664388656616),\n",
       " ('sultan', 0.5376776456832886),\n",
       " ('Queen_Consort', 0.5344247221946716),\n",
       " ('queens', 0.5289887189865112)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar([vec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thats all! \n",
    "# Done!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
